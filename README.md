# ETL 3 FINAL

## Контейнеры

### 1. **MongoDB**
- Основная NoSQL база данных.
- Работает на порту `27017`.
- Данные сохраняются в volume `mongo_data`.

### 2. **PostgreSQL**
- Реляционная база данных, в которой сохраняются результаты работы пайплайнов Airflow.
- Доступ осуществляется через порт `5432`.
- Данные хранятся в volume `pg_data`.
- Параметры подключения:
  - Логин: `user`
  - Пароль: `password`
  - База данных: `mydatabase`

### 3. **pgAdmin**
- Веб-интерфейс для управления PostgreSQL.
- Доступен по адресу `http://localhost:5051`.
- Данные сохраняются в volume `pg_admin_data`.
- Параметры для входа:
  - Email: `admin@admin.com`
  - Пароль: `admin`

### 4. **Генератор данных (faker)**
- Создаёт тестовые данные и загружает их в MongoDB.
- Запускается сразу после старта MongoDB и выполняется один раз по умолчанию.
- Использует подключение:  
  `MONGO_URI=mongodb://mongo:27017/`

### 5. **Airflow**
- Веб-интерфейс доступен по адресу `http://localhost:8080`.
- Работает в режиме `LocalExecutor`.
- DAGs хранятся в папке `./airflow/dags`.
- Используемые подключения:
  - К MongoDB:  
    `MONGO_URI=mongodb://mongo:27017/`
  - К PostgreSQL:  
    `postgresql+psycopg2://user:password@postgres/mydatabase`
- Данные для входа:
  - Логин: `usr`
  - Пароль: `usr`

## Запуск проекта

```sh
git clone https://github.com/Zaozerskikh/etl_3_final
cd etl_3_final
docker-compose up -d --build
```

## Генератор данных

- **Цель:** Создание тестовых данных для проверки работы ETL-процесса.
- **Процесс:**
  - Используется библиотека Faker для генерации 1000 записей.
  - Для каждой сессии происходит следующее:
    - Создаётся уникальный `session_id` (с помощью UUID).
    - Определяется случайное время начала `start_time` в текущем году, а время окончания `end_time` рассчитывается как `start_time` плюс от 1 до 120 минут.
    - Заполняются дополнительные поля: `user_id`, список посещённых страниц (`pages_visited`), сведения об устройстве (`device`) и действия пользователя (`actions`).
  - Все сгенерированные записи вставляются в коллекцию `UserSessions` в MongoDB.
- **Результат:** Коллекция MongoDB наполняется тестовыми данными, готовыми для последующей обработки.

## ETL пайплайн репликации

### 1. Извлечение (extract)
- **Описание:** Подключение к MongoDB и извлечение всех документов из коллекции `UserSessions`.
- **Процесс:**
  - Устанавливается соединение с MongoDB по указанному URI.
  - Из коллекции считываются все документы.
  - Если присутствует поле `_id`, оно конвертируется в строку.
- **Результат:** Получен список документов, готовых для дальнейшей обработки.

### 2. Трансформация (transform)
- **Описание:** Очистка и подготовка данных перед загрузкой.
- **Процесс:**
  - Удаляются дубликаты, определяемые по полю `session_id`.
  - Поле `start_time` обрабатывается, и на его основе создаётся новое поле `partition_date` в формате `YYYY-MM-DD`.
- **Результат:** Формируется набор документов без дублирования, с добавленным полем для партиционирования по дате.

### 3. Загрузка (load)
- **Описание:** Перемещение данных в PostgreSQL с распределением по таблицам, каждая из которых соответствует определённому месяцу.
- **Процесс:**
  - Устанавливается соединение с PostgreSQL.
  - Для каждого документа вычисляется имя таблицы на основе значения `partition_date`.
  - Проверяется наличие таблицы: если таблица отсутствует, она создаётся со следующей структурой:
    - `id` (первичный ключ),
    - `session_id` (уникальное значение),
    - `partition_date` (дата),
    - `data` (JSONB).
  - Документ затем вставляется или обновляется в соответствующей таблице.
- **Результат:** Данные успешно загружены в PostgreSQL и распределены по таблицам согласно месяцам.

### 4. Проверка качества (quality_check)
- **Описание:** Валидация данных после их загрузки.
- **Процесс:**
  - Подключаются все таблицы с партициями из PostgreSQL.
  - **Проверка дублирования:** Для каждой таблицы выполняется запрос на поиск дубликатов по полю `session_id`.
  - **Проверка правильности партиционирования:**
    - Из названия таблицы извлекается ожидаемый год и месяц.
    - Проверяется, что значение поля `partition_date` у каждой записи соответствует этим параметрам.
  - При обнаружении дубликатов или ошибок партиционирования выводятся сообщения об ошибках и генерируется исключение.
- **Результат:** Обеспечивается целостность данных — дубликаты отсутствуют, а все записи размещены в корректных партициях.


# Доп. задание – витрины
## Витрина 1: dm_daily_session_summary

### Описание
Витрина `dm_daily_session_summary` представляет собой агрегированную сводку по сессиям пользователей, сгруппированную по дням. В ней содержится следующая информация:
- Общее число сессий за день.
- Число уникальных пользователей в течение дня.
- Средняя продолжительность сессии (в секундах).

### Источник данных
Данные для витрины агрегируются из всех разделённых таблиц сессий (`rep_usersessions_*`), которые создаются в процессе ETL-процесса. Эти таблицы содержат информацию о сессиях пользователей, включая время начала и окончания сессий, а также идентификаторы пользователей.

### Структура таблицы
Таблица `dm_daily_session_summary` имеет следующую структуру:

| Поле                  | Тип данных | Описание                                        |
|-----------------------|------------|-------------------------------------------------|
| `summary_date`         | DATE       | Дата, за которую собраны данные                |
| `total_sessions`       | INTEGER    | Общее количество сессий на эту дату             |
| `unique_users`         | INTEGER    | Число уникальных пользователей на эту дату     |
| `avg_duration_seconds` | NUMERIC    | Средняя продолжительность сессии в секундах     |

### Логика агрегации
Для каждой разделённой таблицы сессий (все таблицы `rep_usersessions_*`) выполняется агрегация по полю `partition_date`, которое содержит дату сессии. Подсчитывается:
- Общее количество сессий.
- Количество уникальных пользователей.
- Общая продолжительность сессий, которая затем используется для вычисления средней продолжительности.

Результаты агрегируются по дате и обновляются или вставляются в таблицу `dm_daily_session_summary`.

### SQL-запрос для создания таблицы
```sql
CREATE TABLE IF NOT EXISTS dm_daily_session_summary (
    summary_date DATE PRIMARY KEY,
    total_sessions INTEGER,
    unique_users INTEGER,
    avg_duration_seconds NUMERIC
);
```

---

## Витрина 2: dm_device_usage

### Описание
Витрина `dm_device_usage` агрегирует данные об использовании различных устройств и браузеров. В ней подсчитывается количество сессий для каждого типа устройства и браузера.

### Источник данных
Данные для витрины агрегируются из всех разделённых таблиц сессий (`rep_usersessions_*`). Каждый документ сессии содержит строку с информацией о используемом устройстве (параметр `device` в JSON).

### Структура таблицы
Таблица `dm_device_usage` имеет следующую структуру:

| Поле         | Тип данных | Описание                                        |
|--------------|------------|-------------------------------------------------|
| `device_type`| TEXT       | Тип устройства: Mobile или Desktop             |
| `browser`    | TEXT       | Тип браузера (например, Chrome, Firefox, Safari)|
| `sessions_count` | INTEGER | Количество сессий для данного устройства и браузера |

### Логика агрегации
Для каждой разделённой таблицы сессий (все таблицы `rep_usersessions_*`) выполняется агрегация по полю `device`.
Из строки устройства (device) извлекается тип устройства (мобильное или десктопное) и браузер.
Для каждого сочетания типа устройства и браузера подсчитывается количество сессий.

Результаты агрегируются и обновляются в таблице `dm_device_usage`.

### SQL-запрос для создания таблицы
```sql
CREATE TABLE IF NOT EXISTS dm_device_usage (
    device_type TEXT,
    browser TEXT,
    sessions_count INTEGER,
    PRIMARY KEY (device_type, browser)
);
```
